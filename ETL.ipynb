{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformación de Datos \n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Se importan librerias necesarias***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "import numpy as np\n",
    "import json as js\n",
    "import ast \n",
    "import re\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformación de datos: Dataset Steam_games\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Se carga y se convierten en DataFrame para su visualización correcta**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_games = pd.read_json('/Users/carolina/Desktop/Data/Henry - Data Science/M7/Proyecto Individual 1/steam_games.json',lines=True)\n",
    "df1 = steam_games\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Se realiza exploracion de los datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.info()\n",
    "df1.describe()\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Se revisan y se eliminan filas con datos nulos en el DataFrame**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**# Se convierten las columnas con listas a cadenas de texto para poder buscar duplicados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mz/q_bk1n_55k70r74tttm3ps0c0000gn/T/ipykernel_7277/3296340217.py:2: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df1 = df1.applymap(lambda x: tuple(x) if isinstance(x, list) else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicados encontrados:\n",
      "Empty DataFrame\n",
      "Columns: [publisher, genres, app_name, title, url, release_date, tags, reviews_url, specs, price, early_access, id, developer]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Convertir las columnas con listas a cadenas de texto para poder buscar duplicados\n",
    "df1 = df1.applymap(lambda x: tuple(x) if isinstance(x, list) else x)\n",
    "\n",
    "# Encontrar los duplicados\n",
    "duplicados = df1[df1.duplicated()]\n",
    "\n",
    "# Mostrar los duplicados\n",
    "print(\"Duplicados encontrados:\")\n",
    "print(duplicados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Eliminar filas con valores NaN en cualquier columna y se verifica el df**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.dropna()\n",
    "print(df1.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transformar la columna price (tipo de dato, convertir los valores no numericos en NaN y despues rellenar con 0)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['price'] = pd.to_numeric(df1['price'], errors='coerce')  # Se convierte valores no numéricos en NaN\n",
    "df1['price'] = df1['price'].fillna(0)  # Se rellena los NaN con 0 \n",
    "df1['price'] = df1['price'].astype(int)  # Se convierte a tipo entero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Se cambia de tipo de dato la columna 'release_date'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['release_date'] = pd.to_datetime(df1['release_date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Se convierte todas las columnas de tipo 'object' a 'str'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df1.select_dtypes(include=['object']).columns:\n",
    "    df1[col] = df1[col].astype(str)\n",
    "    df1['id'] = df1['id'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Se exporta el archivo para el sistema de recomendación***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_parquet('df1_games.parquet', engine='pyarrow', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columnas_especificas = ['publisher','genres', 'title', 'release_date','price','id','developer']\n",
    "\n",
    "# Crear un nuevo DataFrame con solo las columnas específicas\n",
    "nuevo_df_games = df1[columnas_especificas]\n",
    "\n",
    "# Ver el nuevo DataFrame\n",
    "print(nuevo_df_games)\n",
    "df_games = nuevo_df_games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Se exporta el archivo para la API***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_games.to_parquet('df_games.parquet', engine='pyarrow', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformacion: Dataset user_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Se carga y se convierten en DataFrame para su visualización correcta**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_reviews = [] #Este código está diseñado para leer un archivo JSON línea por línea, convertir cada línea en un diccionario Python y luego agregarlo a una lista llamada list_reviews\n",
    "archivo3 = r'/Users/carolina/Desktop/Data/Henry - Data Science/M7/Proyecto Individual 1/user_reviews.json'\n",
    "with open(archivo3, encoding='utf-8') as file2:\n",
    "    for line2 in file2.readlines():\n",
    "        list_reviews.append(ast.literal_eval(line2))\n",
    "it2= pd.DataFrame(list_reviews)\n",
    "df3 = it2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Desanidar Columna \"reviews\" del Dataframe***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Este codigo funciona para limpiar la columna \"reviews\", convirtiendo cualquier texto que represente una lista o diccionario en una estructura de Python real.\n",
    "df3['reviews'] = df3['reviews'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "# Verificar si hay índices duplicados\n",
    "duplicate_index = df3.index.duplicated()\n",
    "if duplicate_index.any():\n",
    "    print(df3[duplicate_index])  # No se encontraron indices duplicados\n",
    "# Restablecer el índice\n",
    "df3_reset = df3.reset_index(drop=True)\n",
    "# Convertir la columna 'reviews' en listas de diccionarios\n",
    "df3['reviews'] = df3['reviews'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "\n",
    "# Explota las reseñas\n",
    "df_exploded = df3.explode('reviews')\n",
    "\n",
    "# Normaliza la columna 'reviews'\n",
    "df_reviews = pd.json_normalize(df_exploded['reviews'])\n",
    "\n",
    "# Restablece el índice del DataFrame normalizado\n",
    "df_reviews.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Combina los DataFrames\n",
    "df_final_reviews = pd.concat([df_exploded.drop(columns=['reviews']).reset_index(drop=True), df_reviews], axis=1)\n",
    "\n",
    "# Muestra el DataFrame final\n",
    "print(df_final_reviews.head())\n",
    "df_final_reviews\n",
    "df3= df_final_reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Se realiza exploracion de los datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.info()\n",
    "df3.describe()\n",
    "df3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Se revisan y se eliminan filas con datos nulos en el DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.isnull().sum()\n",
    "df3 = df3.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Se convierte las columnas con listas a cadenas de texto para poder buscar duplicados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df3 = df3.applymap(lambda x: tuple(x) if isinstance(x, list) else x)\n",
    "# Encontrar los duplicados\n",
    "duplicados = df3[df3.duplicated()]\n",
    "# Mostrar los duplicados\n",
    "print(\"Duplicados encontrados:\")\n",
    "print(duplicados)\n",
    "df3 = df3.drop_duplicates()\n",
    "# Encontrar los duplicados\n",
    "duplicados = df3[df3.duplicated()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Limpiar los datos en la columna review del DS***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Función para limpiar texto\n",
    "def clean_review(text):\n",
    "    # Eliminar URLs\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text)\n",
    "    # Eliminar caracteres no alfanuméricos excepto espacios\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    # Convertir el texto a minúsculas\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "# Aplicar la limpieza a la columna 'review'\n",
    "df3['review'] = df3['review'].apply(lambda x: clean_review(x) if isinstance(x, str) else '')\n",
    "\n",
    "# Eliminar filas donde 'review' esté vacío o no válido\n",
    "df3 = df3[df3['review'].str.strip() != '']\n",
    "\n",
    "# Eliminar cualquier reseña vacía o NaN\n",
    "df3 = df3.dropna(subset=['review'])\n",
    "\n",
    "print(df3.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Cambiar los tipos de datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['item_id'] = df3['item_id'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Se exporta el archivo para el sistema de recomendación***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_parquet('df3_reviews.parquet', engine='pyarrow', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Se escogen las columnas que se necesitan para realizar las funciones de la API***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columnas_especificas = ['user_id','item_id','posted','recommend', 'review']\n",
    "\n",
    "# Crear un nuevo DataFrame con solo las columnas específicas\n",
    "nuevo_df_items = df3[columnas_especificas]\n",
    "\n",
    "# Ver el nuevo DataFrame\n",
    "print(nuevo_df_items)\n",
    "df_reviews2 = nuevo_df_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Se exporta el archivo para Análisis de sentimiento***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews2.to_parquet('df_reviews2.parquet', engine='pyarrow', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Se exporta para la API**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews.to_parquet('df_reviews.parquet', engine='pyarrow', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformación: Dataset  user_item\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Se carga y se convierten en DataFrame para su visualización correcta**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_items = []  #Este código está diseñado para leer un archivo JSON línea por línea, convertir cada línea en un diccionario Python y luego agregarlo a una lista llamada list_items\n",
    "archivo2 = r'/Users/carolina/Desktop/Data/Henry - Data Science/M7/Proyecto Individual 1/users_items.json'\n",
    "with open(archivo2, encoding='utf-8') as file2:\n",
    "    for line2 in file2.readlines():\n",
    "        list_items.append(ast.literal_eval(line2))\n",
    "\n",
    "it1 = pd.DataFrame(list_items)\n",
    "df2 = it1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Desanidar Columna \"items\" del Dataframe***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convertir la columna 'items' en listas de diccionarios en el DataFrame original\n",
    "df2['items'] = df2['items'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "\n",
    "# Explota las reseñas en el mismo DataFrame original \n",
    "df2 = df2.explode('items')\n",
    "\n",
    "# Normaliza la columna 'items' en el DataFrame original\n",
    "df_items = pd.json_normalize(df2['items'])\n",
    "\n",
    "# Restablece el índice del DataFrame original\n",
    "df_items.reset_index(drop=True, inplace=True)\n",
    "df2.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Combina las columnas normalizadas con el DataFrame original\n",
    "df2 = pd.concat([df2.drop(columns=['items']), df_items], axis=1)\n",
    "\n",
    "# Muestra el DataFrame final\n",
    "print(df2.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Se realiza exploración de los datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5170015 entries, 0 to 5170014\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Dtype  \n",
      "---  ------            -----  \n",
      " 0   user_id           object \n",
      " 1   items_count       int64  \n",
      " 2   steam_id          object \n",
      " 3   user_url          object \n",
      " 4   item_id           object \n",
      " 5   item_name         object \n",
      " 6   playtime_forever  float64\n",
      " 7   playtime_2weeks   float64\n",
      "dtypes: float64(2), int64(1), object(5)\n",
      "memory usage: 315.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df2.info()\n",
    "df2.describe()\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Se revisan y se eliminan filas con datos nulos en el DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.isnull().sum()\n",
    "df2 = df2.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Se verifican y se eliminan duplicados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicados = df2[df2.duplicated()]\n",
    "print(\"Duplicados encontrados:\")\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del DataFrame después de eliminar duplicados: (5110819, 8)\n"
     ]
    }
   ],
   "source": [
    "# Elimina los duplicados, conservando solo la primera aparición\n",
    "df2_sin_duplicados = df2.drop_duplicates()\n",
    "\n",
    "# Verifica el tamaño del DataFrame después de eliminar los duplicados\n",
    "print(f\"Tamaño del DataFrame después de eliminar duplicados: {df2_sin_duplicados.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_items =df2_sin_duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             user_id  items_count           steam_id  \\\n",
      "0  76561197970982479          277  76561197970982479   \n",
      "1  76561197970982479          277  76561197970982479   \n",
      "2  76561197970982479          277  76561197970982479   \n",
      "3  76561197970982479          277  76561197970982479   \n",
      "4  76561197970982479          277  76561197970982479   \n",
      "\n",
      "                                            user_url item_id  \\\n",
      "0  http://steamcommunity.com/profiles/76561197970...      10   \n",
      "1  http://steamcommunity.com/profiles/76561197970...      20   \n",
      "2  http://steamcommunity.com/profiles/76561197970...      30   \n",
      "3  http://steamcommunity.com/profiles/76561197970...      40   \n",
      "4  http://steamcommunity.com/profiles/76561197970...      50   \n",
      "\n",
      "                   item_name  playtime_forever  playtime_2weeks  \n",
      "0             Counter-Strike               6.0              0.0  \n",
      "1      Team Fortress Classic               0.0              0.0  \n",
      "2              Day of Defeat               7.0              0.0  \n",
      "3         Deathmatch Classic               0.0              0.0  \n",
      "4  Half-Life: Opposing Force               0.0              0.0  \n"
     ]
    }
   ],
   "source": [
    "# Eliminar filas con valores NaN en cualquier columna\n",
    "df2_items = df2_items.dropna()\n",
    "\n",
    "# Mostrar el DataFrame después de eliminar filas con NaN\n",
    "print(df2_items.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Se revisan tipos de datos y se cambian si es necesario**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id              object\n",
      "items_count           int64\n",
      "steam_id             object\n",
      "user_url             object\n",
      "item_id              object\n",
      "item_name            object\n",
      "playtime_forever    float64\n",
      "playtime_2weeks     float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(df2_items.dtypes)\n",
    "df_items['item_id'] = df_items['item_id'].astype(str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se exporta para el sistema de recomendación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_items.to_parquet('df2_items.parquet', engine='pyarrow', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Se escogen las columnas que se necesitan para realizar las funciones de la API**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   user_id item_id  items_count  playtime_forever\n",
      "0        76561197970982479      10          277               6.0\n",
      "1        76561197970982479      20          277               0.0\n",
      "2        76561197970982479      30          277               7.0\n",
      "3        76561197970982479      40          277               0.0\n",
      "4        76561197970982479      50          277               0.0\n",
      "...                    ...     ...          ...               ...\n",
      "5170010  76561198329548331  373330            7               0.0\n",
      "5170011  76561198329548331  388490            7               3.0\n",
      "5170012  76561198329548331  521570            7               4.0\n",
      "5170013  76561198329548331  519140            7               3.0\n",
      "5170014  edward_tremethick     NaN            0               NaN\n",
      "\n",
      "[5170015 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "columnas_especificas2 = ['user_id','item_id','items_count','playtime_forever']\n",
    "\n",
    "# Crear un nuevo DataFrame con solo las columnas específicas\n",
    "nuevo_df_items = df2[columnas_especificas2]\n",
    "\n",
    "# Ver el nuevo DataFrame\n",
    "print(nuevo_df_items)\n",
    "df_items = nuevo_df_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items = df_items.dropna(subset=['user_id','item_id','items_count','playtime_forever'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5153209, 4)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_items.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Se exporta para la API**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items.to_parquet('df_items.parquet', engine='pyarrow', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
